import { streamText, LanguageModel, convertToModelMessages, UIMessage } from 'ai';
import { createAzure } from '@ai-sdk/azure';
import { google } from '@ai-sdk/google';
import { createAmazonBedrock } from '@ai-sdk/amazon-bedrock';
import { createOpenAI } from '@ai-sdk/openai';
// Removed fromNodeProviderChain - not needed when using default credential chain
import { getServerSession } from "@/lib/auth/server-session";
import { ErrorFactories } from "@/lib/error-utils";
import { getCurrentUserAction } from "@/actions/db/get-current-user-action";
import { executeSQL, FormattedRow } from "@/lib/db/data-api-adapter";
import { SelectDocument } from "@/types/db-types";
import { Settings } from "@/lib/settings-manager";
import { createLogger, generateRequestId, startTimer } from "@/lib/logger";
import { ensureRDSString, ensureRDSNumber } from "@/lib/type-helpers";
import { getDocumentsByConversationId, getDocumentChunksByDocumentId, getDocumentById } from "@/lib/db/queries/documents";
import { contextMonitor } from "@/lib/monitoring/context-loading-monitor";
import { retrieveKnowledgeForPrompt, formatKnowledgeContext } from "@/lib/assistant-architect/knowledge-retrieval";
// Reasoning model support will be implemented in future AI SDK versions
// import { isReasoningModel } from "@/types/ai-sdk-v5-types";

// Helper function to load complete execution context
async function loadExecutionContext(execId: number) {
  const log = createLogger({ requestId: 'exec-context', route: 'api.chat.stream-final' });
  
  // CRITICAL SAFEGUARD: Validate execution ID
  if (!execId || isNaN(execId) || execId <= 0) {
    log.error('Invalid execution ID provided to loadExecutionContext', { execId });
    return null;
  }
  
  const loadStartTime = Date.now();
  
  try {
    // Start loading context
    
    // Get execution details, prompt results, and ALL assistant context in parallel
    const [executionData, promptResults, allChainPrompts, toolInputFields] = await Promise.all([
      executeSQL(
        `SELECT te.input_data, te.status as exec_status, te.started_at, te.completed_at,
                aa.name as tool_name, aa.description as tool_description,
                te.assistant_architect_id, aa.user_id as assistant_user_id
        FROM tool_executions te
        LEFT JOIN assistant_architects aa ON te.assistant_architect_id = aa.id
        WHERE te.id = :executionId`,
        [{ name: 'executionId', value: { longValue: execId } }]
      ),
      executeSQL(
        `SELECT pr.prompt_id, pr.input_data, pr.output_data, 
                pr.status, pr.started_at, pr.completed_at,
                cp.name as prompt_name, cp.system_context,
                cp.content as prompt_content
        FROM prompt_results pr
        LEFT JOIN chain_prompts cp ON pr.prompt_id = cp.id
        WHERE pr.execution_id = :executionId
        ORDER BY pr.started_at ASC`,
        [{ name: 'executionId', value: { longValue: execId } }]
      ),
      executeSQL(
        `SELECT cp.id, cp.name, cp.content, cp.system_context, cp.position, cp.repository_ids
        FROM chain_prompts cp
        WHERE cp.assistant_architect_id = (
          SELECT assistant_architect_id FROM tool_executions WHERE id = :executionId
        )
        ORDER BY cp.position ASC`,
        [{ name: 'executionId', value: { longValue: execId } }]
      ),
      executeSQL(
        `SELECT tif.name, tif.label, tif.field_type
        FROM tool_input_fields tif
        WHERE tif.assistant_architect_id = (
          SELECT assistant_architect_id FROM tool_executions WHERE id = :executionId
        )
        ORDER BY tif.position ASC`,
        [{ name: 'executionId', value: { longValue: execId } }]
      )
    ]);
    
    if (executionData.length === 0) {
      return null;
    }
    
    const execution = executionData[0];
    
    // Build comprehensive execution context
    let assistantKnowledge = '';
    
    // 1. Include assistant description
    if (execution.tool_description) {
      assistantKnowledge += `\n\nAssistant Purpose:\n${execution.tool_description}`;
    }
    
    // Extract repository IDs from all prompts
    const allRepositoryIds = new Set<number>();
    allChainPrompts.forEach(prompt => {
      if (prompt.repository_ids) {
        const ids = typeof prompt.repository_ids === 'string' ? JSON.parse(prompt.repository_ids) : prompt.repository_ids;
        if (Array.isArray(ids)) {
          ids.forEach(id => allRepositoryIds.add(Number(id)));
        }
      }
    });
    const repositoryIds = Array.from(allRepositoryIds);
    
    // 2. Include ALL system contexts from chain prompts
    // Process chain prompts
    
    // SAFEGUARD: Robust system context extraction with validation
    const systemContexts = allChainPrompts
      .map((row) => {
        // RDS Data API returns snake_case column names
        const context = row.system_context || row.systemContext || '';
        
        // SAFEGUARD: Log if we find empty contexts
        if (!context || String(context).trim() === '') {
          const log = createLogger({ requestId: 'exec-context', route: 'api.chat.stream-final' });
          log.warn('Empty system_context found for chain prompt');
        }
        
        return String(context);
      })
      .filter(ctx => ctx.trim() !== '');
    
    // SAFEGUARD: Alert if no system contexts found when we expect them
    if (systemContexts.length === 0 && allChainPrompts.length > 0) {
      log.error('[stream-final] WARNING: No system contexts found despite having chain prompts!', {
        chainPromptsCount: allChainPrompts.length,
        firstPromptKeys: allChainPrompts[0] ? Object.keys(allChainPrompts[0]) : []
      });
    }
    
    if (systemContexts.length > 0) {
      assistantKnowledge += `\n\nAssistant Knowledge Base (System Contexts):\n${systemContexts.join('\n\n---\n\n')}`;
    }
    
    // 3. Include all prompt templates
    const promptTemplates = allChainPrompts
      .map(prompt => `${prompt.name}: ${prompt.content}`)
      .join('\n\n');
    
    if (promptTemplates) {
      assistantKnowledge += `\n\nAssistant Prompt Templates:\n${promptTemplates}`;
    }
    
    // 4. Format user inputs with field labels
    let formattedInputs = '';
    if (execution.input_data) {
      const inputValues = typeof execution.input_data === 'string' 
        ? JSON.parse(execution.input_data) 
        : execution.input_data;
      
      formattedInputs = '\n\nUser Inputs:\n';
      for (const field of toolInputFields) {
        const fieldName = String(field.name);
        const value = inputValues[fieldName];
        if (value !== undefined && value !== null && value !== '') {
          formattedInputs += `- ${field.label}: ${value}\n`;
        }
      }
    }
    
    const executionContext = `\n\nExecution Context:
Tool: ${execution.tool_name}
Description: ${execution.tool_description}
Execution Status: ${execution.exec_status}
${formattedInputs}
${assistantKnowledge}

Execution Results:
${promptResults.map((pr, idx) => `
${idx + 1}. ${pr.prompt_name || 'Prompt'}:
   Prompt Template: ${pr.prompt_content || 'N/A'}
   Processed Input: ${JSON.stringify(pr.input_data || {})}
   Output: ${pr.output_data || ''}
   Status: ${pr.status || 'unknown'}`).join('\n')}

IMPORTANT: You have access to ALL the information above, including:
- The complete assistant knowledge base with all system contexts
- All prompt templates showing what the assistant knows
- The user's original inputs
- The execution results

Use ALL of this information to answer questions accurately. When asked about specific knowledge (like "10 elements" or any other content), refer to the Assistant Knowledge Base section above.`;
    
    // SAFEGUARD: Comprehensive validation before returning
    const contextValidation = {
      executionId: execId,
      hasAssistantKnowledge: assistantKnowledge.length > 0,
      promptResultsCount: promptResults.length,
      allChainPromptsCount: allChainPrompts.length,
      systemContextsCount: systemContexts.length,
      toolInputFieldsCount: toolInputFields.length,
      contextLength: executionContext.length,
      // CRITICAL: Validate we have meaningful content
      hasMinimumContent: executionContext.length > 500,
      hasSystemContexts: systemContexts.length > 0,
      hasPromptTemplates: promptTemplates.length > 0
    };
    
    // Context loaded successfully
    
    // SAFEGUARD: Warn if context seems incomplete
    if (!contextValidation.hasMinimumContent || !contextValidation.hasSystemContexts) {
      log.warn('[stream-final] Context may be incomplete!', contextValidation);
    }
    
    // SAFEGUARD: Track metrics for monitoring
    contextMonitor.trackContextLoad(loadStartTime, {
      executionId: execId,
      systemContexts,
      chainPrompts: allChainPrompts,
      contextLength: executionContext.length
    });
    
    // Return both the formatted context and the complete data
    return {
      executionContext,
      completeData: {
        execution,
        promptResults,
        allChainPrompts,
        toolInputFields,
        assistantKnowledge,
        systemContexts,
        repositoryIds
      }
    };
  } catch (error) {
    // SAFEGUARD: Detailed error logging
    log.error('[stream-final] Error loading execution context:', {
      error: error instanceof Error ? error.message : String(error),
      stack: error instanceof Error ? error.stack : undefined,
      executionId: execId
    });
    
    // SAFEGUARD: Track error in monitoring
    contextMonitor.trackContextLoad(loadStartTime, {
      executionId: execId,
      error: error instanceof Error ? error : new Error(String(error))
    });
    
    return null;
  }
}
export async function POST(req: Request) {
  const requestId = generateRequestId();
  const timer = startTimer("api.chat.stream-final");
  const log = createLogger({ requestId, route: "api.chat.stream-final" });
  
  log.info("POST /api/chat/stream-final - Processing streaming chat request");
  
  try {
    const session = await getServerSession();
    if (!session) {
      log.warn("Unauthorized - No session");
      timer({ status: "error", reason: "unauthorized" });
      return new Response('Unauthorized', { status: 401 });
    }

    const body = await req.json();
  const { messages, modelId: textModelId, conversationId: existingConversationId, documentId, source, executionId, context } = body;
    
    // Process chat request

  // Get model info - handle both numeric ID and string model_id
  const isNumericId = typeof textModelId === 'number' || /^\d+$/.test(String(textModelId));
  
  let modelResult;
  if (isNumericId) {
    // Try to get model by numeric ID
    const modelQuery = `
      SELECT id, name, provider, model_id
      FROM ai_models
      WHERE id = :modelId AND active = true AND chat_enabled = true
      LIMIT 1
    `;
    modelResult = await executeSQL<FormattedRow>(modelQuery, [
      { name: 'modelId', value: { longValue: Number(textModelId) } }
    ]);
  } else {
    // Get model by string model_id
    const modelQuery = `
      SELECT id, name, provider, model_id
      FROM ai_models
      WHERE model_id = :modelId AND active = true AND chat_enabled = true
      LIMIT 1
    `;
    modelResult = await executeSQL<FormattedRow>(modelQuery, [
      { name: 'modelId', value: { stringValue: String(textModelId) } }
    ]);
  }
  
  // If model not found, fall back to first available chat-enabled model
  if (!modelResult.length) {
    const fallbackQuery = `
      SELECT id, name, provider, model_id
      FROM ai_models
      WHERE active = true AND chat_enabled = true
      ORDER BY id
      LIMIT 1
    `;
    modelResult = await executeSQL<FormattedRow>(fallbackQuery);
    
    if (!modelResult.length) {
      return new Response("No chat-enabled models available", { status: 503 });
    }
  }
  
  const aiModel = modelResult[0];
  
  // Model resolved
  
  // Retrieve execution context BEFORE creating conversation so we can store it
  let executionContext = "";
  let fullContext = context;
  let execIdToUse = null;
  let completeExecutionData = null;
  
  // For new conversations with executionId, load context first
  if (!existingConversationId && executionId) {
    // SAFEGUARD: Strict validation of executionId
    
    // Parse executionId to ensure it's a number
    execIdToUse = typeof executionId === 'string' ? parseInt(executionId, 10) : executionId;
    
    // SAFEGUARD: Reject 'streaming' or other invalid values immediately
    if (executionId === 'streaming' || executionId === 'undefined' || executionId === 'null') {
      log.error('[stream-final] Invalid executionId received:', { executionId, type: typeof executionId });
      execIdToUse = null;
    }
    
    // Load context for new conversation
    
    if (!isNaN(execIdToUse) && execIdToUse > 0) {
      // Load the complete execution context
      const execResult = await loadExecutionContext(execIdToUse);
      if (execResult) {
        executionContext = execResult.executionContext;
        completeExecutionData = execResult.completeData;
        // Store the complete execution data for the conversation context
        fullContext = completeExecutionData;
        // Context loaded successfully
      } else {
        // SAFEGUARD: Critical error if context loading fails
        log.error('[stream-final] CRITICAL: Failed to load execution context for valid executionId!', {
          executionId: execIdToUse
        });
      }
    }
  }
  
  // Handle conversation
  let conversationId = existingConversationId;
  
  if (!conversationId) {
    const currentUser = await getCurrentUserAction();
    if (!currentUser.isSuccess) {
      return new Response("Unauthorized", { status: 401 });
    }

    const insertQuery = `
      INSERT INTO conversations (title, user_id, model_id, source, execution_id, context)
      VALUES (:title, :userId, :modelId, :source, :executionId, :context::jsonb)
      RETURNING id
    `;
    const newConversation = await executeSQL(insertQuery, [
      { name: 'title', value: { stringValue: messages[0].content.substring(0, 100) } },
      { name: 'userId', value: { longValue: currentUser.data.user.id } },
      { name: 'modelId', value: { longValue: ensureRDSNumber(aiModel.id) } },
      { name: 'source', value: { stringValue: source || "chat" } },
      { name: 'executionId', value: (() => {
        if (!executionId) return { isNull: true };
        const parsed = typeof executionId === 'string' ? parseInt(executionId, 10) : executionId;
        return isNaN(parsed) ? { isNull: true } : { longValue: parsed };
      })() },
      { name: 'context', value: fullContext ? { stringValue: JSON.stringify(fullContext) } : { isNull: true } }
    ]);
    conversationId = newConversation[0].id;
  }

  // Save user message (users don't have a model_id, only assistant messages do)
  const userMessage = messages[messages.length - 1];
  await executeSQL(
    `INSERT INTO messages (conversation_id, role, content) VALUES (:conversationId, :role, :content)`,
    [
      { name: 'conversationId', value: { longValue: conversationId } },
      { name: 'role', value: { stringValue: userMessage.role } },
      { name: 'content', value: { stringValue: userMessage.content } }
    ]
  );

  // Get the model
  let model: LanguageModel;
  
  try {
    switch (aiModel.provider) {
      case 'openai': {
        const key = await Settings.getOpenAI();
        log.info('[stream-final] OpenAI key retrieval', { hasKey: !!key, keyLength: key?.length });
        if (!key) {
          log.error('[stream-final] OpenAI API key not found in settings');
          throw ErrorFactories.sysConfigurationError('OpenAI API key not configured');
        }
        const openai = createOpenAI({ apiKey: key });
        const modelId = ensureRDSString(aiModel.modelId);
        log.info('[stream-final] Using OpenAI model', { modelId });
        model = openai(modelId);
        log.info('[stream-final] OpenAI model initialized successfully');
        break;
      }
    case 'azure': {
      const config = await Settings.getAzureOpenAI();
      if (!config.key || !config.resourceName) throw ErrorFactories.sysConfigurationError('Azure OpenAI not configured');
      const azure = createAzure({ apiKey: config.key, resourceName: config.resourceName });
      model = azure(ensureRDSString(aiModel.modelId)) as unknown as LanguageModel;
      break;
    }
    case 'google': {
      const key = await Settings.getGoogleAI();
      if (!key) throw ErrorFactories.sysConfigurationError('Google API key not configured');
      process.env.GOOGLE_GENERATIVE_AI_API_KEY = key;
      model = google(ensureRDSString(aiModel.modelId)) as unknown as LanguageModel;
      break;
    }
    case 'amazon-bedrock': {
      log.info('[stream-final] Starting Bedrock initialization for model:', aiModel.modelId);
      
      try {
        const config = await Settings.getBedrock();
        log.info('[stream-final] Bedrock settings retrieved:', {
          hasAccessKey: !!config.accessKeyId,
          hasSecretKey: !!config.secretAccessKey,
          region: config.region || 'us-east-1',
          environment: process.env.AWS_EXECUTION_ENV || 'local',
          lambdaFunction: process.env.AWS_LAMBDA_FUNCTION_NAME
        });
        
        const bedrockOptions: Parameters<typeof createAmazonBedrock>[0] = {
          region: config.region || 'us-east-1'
        };
        
        // In AWS Lambda, always use IAM role credentials (ignore stored credentials)
        const isAwsLambda = !!process.env.AWS_LAMBDA_FUNCTION_NAME;
        
        if (config.accessKeyId && config.secretAccessKey && !isAwsLambda) {
          // Only use stored credentials for local development
          log.info('[stream-final] Using explicit credentials from settings (local dev)');
          bedrockOptions.accessKeyId = config.accessKeyId;
          bedrockOptions.secretAccessKey = config.secretAccessKey;
        } else {
          // AWS environment or no stored credentials - let SDK handle credentials automatically
          log.info('[stream-final] Using default AWS credential chain', { isAwsLambda });
          // Don't set any credentials - let the SDK use the default credential provider chain
          // This will use IAM role credentials in Lambda, which work properly
        }
        
        log.info('[stream-final] Creating Bedrock client with options:', {
          region: bedrockOptions.region,
          hasAccessKeyId: !!bedrockOptions.accessKeyId,
          hasSecretAccessKey: !!bedrockOptions.secretAccessKey,
          hasSessionToken: !!bedrockOptions.sessionToken
        });
        
        const bedrock = createAmazonBedrock(bedrockOptions);
        model = bedrock(ensureRDSString(aiModel.modelId)) as unknown as LanguageModel;
        
        log.info('[stream-final] Bedrock model created successfully');
      } catch (error) {
        log.error('[stream-final] BEDROCK INITIALIZATION FAILED:', {
          modelId: aiModel.modelId,
          provider: aiModel.provider,
          error: error instanceof Error ? {
            name: error.name,
            message: error.message,
            stack: error.stack,
            ...Object.getOwnPropertyNames(error).reduce((acc: Record<string, unknown>, key) => {
              if (!['name', 'message', 'stack'].includes(key)) {
                acc[key] = (error as unknown as Record<string, unknown>)[key];
              }
              return acc;
            }, {} as Record<string, unknown>)
          } : String(error),
          environment: {
            AWS_REGION: process.env.AWS_REGION,
            AWS_EXECUTION_ENV: process.env.AWS_EXECUTION_ENV,
            AWS_LAMBDA_FUNCTION_NAME: process.env.AWS_LAMBDA_FUNCTION_NAME,
            NODE_ENV: process.env.NODE_ENV
          }
        });
        throw error;
      }
      break;
    }
    default:
      throw ErrorFactories.validationFailed([{ field: 'provider', message: `Unknown provider: ${ensureRDSString(aiModel.provider)}` }]);
    }
  } catch (modelError) {
    log.error('[stream-final] Model initialization error:', modelError);
    throw ErrorFactories.externalServiceError('AI Model', modelError instanceof Error ? modelError : new Error('Unknown error'));
  }

  // Get all messages for context
  const allMessages = await executeSQL<FormattedRow>(
    `SELECT role, content FROM messages WHERE conversation_id = :conversationId ORDER BY created_at ASC`,
    [{ name: 'conversationId', value: { longValue: conversationId } }]
  );

  // --- Fetch documents and relevant content for AI context ---
  let documentContext = "";
  try {
    let documents: SelectDocument[] = [];
    
    // If we have a conversationId, get documents linked to it
    if (conversationId) {
      documents = await getDocumentsByConversationId({ conversationId: conversationId });
    }
    
    // If a documentId was provided, also fetch that specific document
    if (documentId) {
      const singleDoc = await getDocumentById({ id: documentId });
      if (singleDoc && !documents.find((d: SelectDocument) => d.id === documentId)) {
        documents.push(singleDoc);
        // Added document to context
      }
    }
    
    // Process documents for context
    
    if (documents.length > 0) {
      // Found documents for conversation
      // Get the user's latest message for context search
      const latestUserMessage = messages[messages.length - 1].content;
      
      // Get document chunks for all documents
      const documentChunksPromises = documents.map(doc => 
        getDocumentChunksByDocumentId({ documentId: doc.id })
      );
      const documentChunksArrays = await Promise.all(documentChunksPromises);
      let allDocumentChunks = documentChunksArrays.flat();
      
      // If no chunks found and we just uploaded a document, wait a bit and retry
      if (allDocumentChunks.length === 0 && documentId) {
        // Wait for chunks to be saved
        await new Promise(resolve => setTimeout(resolve, 500));
        
        const retryChunksPromises = documents.map(doc => 
          getDocumentChunksByDocumentId({ documentId: doc.id })
        );
        const retryChunksArrays = await Promise.all(retryChunksPromises);
        allDocumentChunks = retryChunksArrays.flat();
      }
      
      // Process document chunks

      // Simple keyword matching to find relevant chunks
      const generalDocumentQueries = ['this', 'document', 'file', 'pdf', 'uploaded', 'attachment'];
      const isGeneralDocumentQuery = generalDocumentQueries.some(term => 
        latestUserMessage.toLowerCase().includes(term)
      );
      
      let relevantChunks = [];
      
      if (isGeneralDocumentQuery || latestUserMessage.toLowerCase().includes('summar')) {
        relevantChunks = allDocumentChunks.slice(0, 5); // Limit to first 5 chunks
      } else {
        relevantChunks = allDocumentChunks
          .filter(chunk => {
            const content = chunk.content.toLowerCase();
            const message = latestUserMessage.toLowerCase();
            const keywords = message.split(/\s+/).filter((word: string) => word.length > 2);
            return keywords.some((keyword: string) => content.includes(keyword));
          })
          .slice(0, 3); // Top 3 most relevant chunks
      }

      // If no chunks matched but we have documents, include at least the first chunk
      if (relevantChunks.length === 0 && allDocumentChunks.length > 0) {
        relevantChunks = allDocumentChunks.slice(0, 3);
      }

      if (relevantChunks.length > 0) {
        const documentNames = documents.map(doc => doc.name).join(", ");
        documentContext = `\n\nRelevant content from uploaded documents (${documentNames}):\n\n${
          relevantChunks.map((chunk, idx) => 
            `[Document Excerpt ${idx + 1}]:\n${chunk.content}`
          ).join('\n\n')
        }\n\nPlease use this document content to answer the user's questions when relevant.`;
        // Include relevant chunks in context
      } else if (allDocumentChunks.length === 0 && documents.length > 0) {
        documentContext = `\n\nNote: A document was uploaded but its content could not be extracted or is still being processed. The document name is: ${documents.map(d => d.name).join(", ")}`;
        log.warn(`Document exists but no chunks found for documents: ${documents.map(d => d.id).join(", ")}`);
      } else {
        // No relevant chunks found
      }
    }
  } catch (docError) {
    log.error("Error fetching document context", { 
      error: docError instanceof Error ? docError.message : String(docError),
      conversationId: conversationId,
      documentId
    });
    // Continue without document context if there's an error
  }

  // Handle existing conversations - retrieve stored context
  if (existingConversationId && !executionContext) {
    const parsedConvId = typeof existingConversationId === 'string' ? parseInt(existingConversationId, 10) : existingConversationId;
    if (!isNaN(parsedConvId) && parsedConvId > 0) {
      const conversationData = await executeSQL(
        `SELECT c.context, c.execution_id
        FROM conversations c
        WHERE c.id = :conversationId`,
        [{ name: 'conversationId', value: { longValue: parsedConvId } }]
      );
      
      if (conversationData.length > 0) {
        const conversation = conversationData[0];
        
        // Try to use stored context first
        try {
          const contextStr = conversation.context as string | null;
          if (contextStr) {
            fullContext = JSON.parse(contextStr);
            
            // If we have stored context with execution data, use it
            if (fullContext && fullContext.execution) {
              // Using stored context from conversation
              
              // Build execution context from stored data
              const stored = fullContext;
              executionContext = `\n\nExecution Context:
Tool: ${stored.execution.tool_name}
Description: ${stored.execution.tool_description}
${stored.formattedInputs || ''}
${stored.assistantKnowledge || ''}

Execution Results:
${stored.promptResults ? stored.promptResults.map((pr: { prompt_name: string; output_data: string; prompt_status: string }, idx: number) => `
${idx + 1}. ${pr.prompt_name}:
   Output: ${pr.output_data}
   Status: ${pr.prompt_status}`).join('\n') : 'No results available'}

IMPORTANT: You have access to ALL the information above. Use it to answer questions accurately.`;
            }
          }
        } catch (parseError) {
          log.warn('Failed to parse conversation context', { 
            conversationId: parsedConvId,
            error: parseError instanceof Error ? parseError.message : 'Unknown error' 
          });
        }
        
        // If no stored context but we have execution_id, load it
        if (!executionContext && conversation.execution_id) {
          execIdToUse = conversation.execution_id;
        }
      }
    }
  }
  
  // Load execution context if needed
  if (!executionContext && execIdToUse) {
    // Validate executionId
    const execId = typeof execIdToUse === 'number' ? execIdToUse : parseInt(String(execIdToUse), 10);
    if (!isNaN(execId) && execId > 0) {
      const result = await loadExecutionContext(execId);
      if (result) {
        executionContext = result.executionContext;
        // Store the complete data for future use
        if (!fullContext) {
          fullContext = result.completeData;
        }
      }
    }
  }
  
  // Dynamic knowledge retrieval for assistant execution conversations
  let knowledgeContext = "";
  if (source === "assistant_execution" && fullContext?.repositoryIds && fullContext.repositoryIds.length > 0) {
    try {
      // Get the user's latest message for knowledge retrieval
      const latestUserMessage = messages[messages.length - 1].content;
      
      // Get assistant owner's cognito_sub if available
      let assistantOwnerSub: string | undefined;
      if (fullContext.completeData?.execution?.assistant_user_id) {
        const assistantOwnerQuery = `
          SELECT u.cognito_sub 
          FROM users u 
          WHERE u.id = :userId
        `;
        const ownerResult = await executeSQL<{ cognito_sub: string }>(assistantOwnerQuery, [
          { name: 'userId', value: { longValue: fullContext.completeData.execution.assistant_user_id } }
        ]);
        assistantOwnerSub = ownerResult[0]?.cognito_sub;
      }
      
      // Retrieve relevant knowledge based on the user's question
      const knowledgeChunks = await retrieveKnowledgeForPrompt(
        latestUserMessage,
        fullContext.repositoryIds,
        session.sub,
        assistantOwnerSub,
        {
          maxChunks: 10,
          maxTokens: 4000,
          searchType: 'hybrid',
          vectorWeight: 0.8,
          similarityThreshold: 0.6 // Lower threshold for follow-up questions
        }
      );
      
      if (knowledgeChunks.length > 0) {
        knowledgeContext = `\n\n${formatKnowledgeContext(knowledgeChunks)}\n\nUse this knowledge to answer the user's question if relevant.`;
        log.info(`Retrieved ${knowledgeChunks.length} knowledge chunks for follow-up conversation`);
      }
    } catch (knowledgeError) {
      log.error('Error retrieving knowledge for follow-up:', knowledgeError);
      // Continue without dynamic knowledge retrieval
    }
  }

  // Build system prompt based on source
  let systemPrompt = source === "assistant_execution"
    ? `You are a helpful AI assistant having a follow-up conversation about the results of an AI tool execution. 

Key responsibilities:
1. Use the execution context provided to answer questions accurately about the tool execution
2. Reference specific prompt results when relevant to the user's questions
3. If asked about inputs, outputs, or the process, refer to the detailed execution history
4. When asked about the knowledge, context, or information the assistant was given, refer to the "Assistant Knowledge Base" section
5. When asked questions that require information from the knowledge repositories, use the dynamically retrieved knowledge to provide accurate answers
6. Stay focused on topics related to the execution results and the assistant's capabilities
7. If a question is completely unrelated to the execution, politely suggest starting a new chat

Remember: You have access to:
- The complete execution history including all inputs, outputs, and prompt results
- The assistant's knowledge base and system context that was used during execution
- The assistant's instructions and configuration
- Dynamic knowledge retrieval from the same repositories used during execution (when relevant to your question)
Use all this information to provide accurate and helpful responses about both what happened and why.`
    : "You are a helpful AI assistant.";
  
  systemPrompt += documentContext;
  systemPrompt += executionContext;
  systemPrompt += knowledgeContext;

  // Prepare messages for streaming - exactly as shown in AI SDK docs
  // Use the messages directly from the request body

  // Start streaming

  // Stream the response with reasoning support
  log.info('[stream-final] About to call streamText', {
    modelProvider: aiModel.provider,
    modelId: aiModel.modelId,
    messageCount: messages ? messages.length : 0,
    lastMessage: messages && messages.length > 0 ? messages[messages.length - 1]?.content?.substring(0, 100) : 'no messages'
  });

  // streamText returns a streaming result immediately - don't await it
  const result = streamText({
      model,
      system: systemPrompt,
      messages: convertToModelMessages(messages),
      onFinish: async ({ text, reasoning, usage }) => {
        // Stream finished
        log.info('[stream-final] Stream finished', { 
          hasText: !!text, 
          textLength: text?.length || 0,
          hasReasoning: !!reasoning,
          hasUsage: !!usage 
        });
        
        // Save assistant message with model tracking
        if (text && text.length > 0) {
        try {
          const insertQuery = `
            INSERT INTO messages (conversation_id, role, content, model_id, reasoning_content, token_usage) 
            VALUES (:conversationId, :role, :content, :modelId, :reasoningContent, :tokenUsage::jsonb)
          `;
          
          await executeSQL<FormattedRow>(
            insertQuery,
            [
              { name: 'conversationId', value: { longValue: conversationId } },
              { name: 'role', value: { stringValue: 'assistant' } },
              { name: 'content', value: { stringValue: text } },
              { name: 'modelId', value: { longValue: ensureRDSNumber(aiModel.id) } },
              { name: 'reasoningContent', value: reasoning ? { stringValue: typeof reasoning === 'string' ? reasoning : JSON.stringify(reasoning) } : { isNull: true } },
              { name: 'tokenUsage', value: usage ? { stringValue: JSON.stringify(usage) } : { isNull: true } }
            ]
          );
          // Assistant response saved with model tracking
          log.info('Assistant message saved with model tracking', {
            conversationId,
            modelId: aiModel.id,
            hasReasoning: !!reasoning,
            hasUsage: !!usage
          });
        } catch (error) {
          log.error('[stream-final] Error saving response:', error);
        }
      } else {
        log.warn('[stream-final] No text to save - streaming completed without content');
      }
    }
  });

  // Return the stream with conversation ID in header
  log.info("Stream started successfully", { conversationId });
  timer({ status: "success", conversationId });
  
  // Return the stream for useChat compatibility
  // According to AI SDK v5 docs, streamText result has toUIMessageStreamResponse method
  const response = result.toUIMessageStreamResponse();
  // Add conversation ID header for new conversations
  if (!existingConversationId && conversationId) {
    response.headers.set('X-Conversation-Id', conversationId.toString());
  }
  return response;
  } catch (error) {
    timer({ status: "error" });
    
    // Enhanced error logging
    const errorDetails = error instanceof Error ? {
      message: error.message,
      name: error.name,
      stack: error.stack,
      cause: error.cause
    } : String(error);
    
    log.error('Error in chat stream', {
      error: errorDetails,
      requestId
    });
    
    // Return a proper error response for non-streaming errors
    // Check if this is a critical error that should stop execution
    if (error instanceof Error && error.message.includes('Model not found')) {
      return new Response('Model not found', { status: 404, headers: { 'X-Request-Id': requestId } });
    }
    
    // Return a more detailed error response
    return new Response(
      JSON.stringify({
        error: 'Failed to process chat request',
        details: error instanceof Error ? error.message : 'Unknown error',
        requestId
      }),
      { 
        status: 500, 
        headers: { 
          'Content-Type': 'application/json',
          'X-Request-Id': requestId 
        } 
      }
    );
  }
}