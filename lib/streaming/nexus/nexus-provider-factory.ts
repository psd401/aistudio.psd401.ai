import { LanguageModel } from 'ai';
import { createProviderModel, createProviderModelWithCapabilities } from '@/app/api/chat/lib/provider-factory';
import { createLogger, generateRequestId, sanitizeForLogging } from '@/lib/logger';
import { ErrorFactories } from '@/lib/error-utils';
import { executeSQL } from './db-helpers';
import { transformSnakeToCamel } from '@/lib/db/field-mapper';
import type { ProviderCapabilities } from '@/lib/streaming/types';

const log = createLogger({ module: 'nexus-provider-factory' });

export interface NexusModelOptions {
  conversationId?: string;
  enableCaching?: boolean;
  enableOptimizations?: boolean;
  routingStrategy?: 'cost' | 'latency' | 'quality' | 'intelligent';
  reasoningEffort?: 'minimal' | 'low' | 'medium' | 'high';
  responseMode?: 'standard' | 'flex' | 'priority';
  backgroundMode?: boolean;
  thinkingBudget?: number;
  useResponsesAPI?: boolean;
  enablePromptCache?: boolean;
  enableContextCache?: boolean;
}

export interface NexusModelCapabilities {
  // Base capabilities from provider
  supportsReasoning: boolean;
  supportsThinking: boolean;
  supportsToolCalls: boolean;
  supportsImages: boolean;
  supportsAudio: boolean;
  maxTimeoutMs: number;
  maxTokens?: number;
  
  // Enhanced capabilities for Nexus features
  responsesAPI?: boolean;
  promptCaching?: boolean;
  contextCaching?: boolean;
  artifacts?: boolean;
  canvas?: boolean;
  webSearch?: boolean;
  codeInterpreter?: boolean;
  grounding?: boolean;
  codeExecution?: boolean;
  computerUse?: boolean;
  workspaceTools?: boolean;
  mcpSupport?: boolean;
  
  // Performance characteristics
  costPerToken?: number;
  averageLatency?: number;
  maxConcurrency?: number;
  supportsBatching?: boolean;
}

export interface NexusLanguageModel {
  // Enhanced model with Nexus-specific features
  model: LanguageModel;
  capabilities: NexusModelCapabilities;
  providerMetadata: {
    provider: string;
    modelId: string;
    pricing?: {
      inputCostPerToken: number;
      outputCostPerToken: number;
      cachingDiscount?: number;
    };
    limits?: {
      maxTokens: number;
      maxRequests: number;
      contextWindow: number;
    };
  };
  
  // Nexus-specific methods
  enableCaching?(): void;
  getCacheMetrics?(): Promise<CacheMetrics>;
  estimateCost?(tokens: number): number;
}

export interface CacheMetrics {
  hitRate: number;
  totalRequests: number;
  tokensSaved: number;
  costSaved: number;
}

/**
 * Enhanced provider factory for Nexus that extends the base provider factory
 * with advanced features like caching, optimization, and provider-specific capabilities
 */
export class NexusProviderFactory {
  private responseCache: ResponseCacheManager;
  private costOptimizer: CostOptimizer;
  private metricsCollector: MetricsCollector;
  
  constructor() {
    this.responseCache = new ResponseCacheManager();
    this.costOptimizer = new CostOptimizer();
    this.metricsCollector = new MetricsCollector();
  }
  
  /**
   * Create an enhanced Nexus model with advanced capabilities
   */
  async createNexusModel(
    provider: string,
    modelId: string,
    options: NexusModelOptions = {}
  ): Promise<NexusLanguageModel> {
    const requestId = generateRequestId();
    const startTime = Date.now();
    
    log.info('Creating Nexus model', {
      requestId,
      provider,
      modelId,
      options: sanitizeForLogging(options)
    });
    
    try {
      // Use existing factory for base model creation with capabilities
      const { model, capabilities } = await createProviderModelWithCapabilities(
        provider, 
        modelId,
        {
          reasoningEffort: options.reasoningEffort,
          responseMode: options.responseMode,
          backgroundMode: options.backgroundMode,
          thinkingBudget: options.thinkingBudget
        }
      );
      
      // Enhance capabilities with Nexus-specific features
      const nexusCapabilities = await this.enhanceCapabilities(provider, modelId, capabilities, options);
      
      // Create enhanced model wrapper
      const nexusModel = await this.wrapWithNexusFeatures(model, {
        provider,
        modelId,
        capabilities: nexusCapabilities,
        options,
        requestId
      });
      
      // Record metrics
      await this.metricsCollector.recordModelCreation({
        provider,
        modelId,
        capabilities: nexusCapabilities,
        creationTime: Date.now() - startTime,
        requestId
      });
      
      log.info('Nexus model created successfully', {
        requestId,
        provider,
        modelId,
        capabilities: {
          supportsReasoning: nexusCapabilities.supportsReasoning,
          supportsThinking: nexusCapabilities.supportsThinking,
          responsesAPI: nexusCapabilities.responsesAPI,
          caching: nexusCapabilities.promptCaching || nexusCapabilities.contextCaching
        }
      });
      
      return nexusModel;
      
    } catch (error) {
      log.error('Failed to create Nexus model', {
        requestId,
        provider,
        modelId,
        error: error instanceof Error ? error.message : String(error)
      });
      throw error;
    }
  }
  
  /**
   * Enhance base capabilities with provider-specific Nexus features
   */
  private async enhanceCapabilities(
    provider: string,
    modelId: string,
    baseCapabilities: ProviderCapabilities,
    options: NexusModelOptions
  ): Promise<NexusModelCapabilities> {
    // Get model info from database
    const modelInfo = await this.getModelInfoFromDatabase(provider, modelId);
    
    const enhanced: NexusModelCapabilities = {
      // Base capabilities from provider
      supportsReasoning: baseCapabilities.supportsReasoning,
      supportsThinking: baseCapabilities.supportsThinking,
      supportsToolCalls: false, // These would be detected from DB or model patterns
      supportsImages: false,
      supportsAudio: false,
      maxTimeoutMs: baseCapabilities.maxTimeoutMs,
      maxTokens: modelInfo?.maxTokens,
      // Initialize Nexus-specific capabilities
      responsesAPI: false,
      promptCaching: false,
      contextCaching: false,
      artifacts: false,
      canvas: false,
      webSearch: false,
      codeInterpreter: false,
      grounding: false,
      codeExecution: false,
      computerUse: false,
      workspaceTools: false,
      mcpSupport: true, // All providers support MCP through our adapter
      supportsBatching: false
    };
    
    // Use nexus_capabilities from database if available
    if (modelInfo?.nexusCapabilities) {
      try {
        const nexusCaps = modelInfo.nexusCapabilities;
        // Apply all capabilities from database
        enhanced.responsesAPI = nexusCaps.responsesAPI || false;
        enhanced.promptCaching = nexusCaps.promptCaching || false;
        enhanced.contextCaching = nexusCaps.contextCaching || false;
        enhanced.artifacts = nexusCaps.artifacts || false;
        enhanced.canvas = nexusCaps.canvas || false;
        enhanced.webSearch = nexusCaps.webSearch || false;
        enhanced.codeInterpreter = nexusCaps.codeInterpreter || false;
        enhanced.grounding = nexusCaps.grounding || false;
        enhanced.codeExecution = nexusCaps.codeExecution || false;
        enhanced.computerUse = nexusCaps.computerUse || false;
        enhanced.workspaceTools = nexusCaps.workspaceTools || false;
        enhanced.supportsReasoning = nexusCaps.reasoning || baseCapabilities.supportsReasoning;
        enhanced.supportsThinking = nexusCaps.thinking || baseCapabilities.supportsThinking;
      } catch (error) {
        log.warn('Failed to parse nexus capabilities from database', {
          provider,
          modelId,
          nexusCapabilities: modelInfo?.nexusCapabilities,
          error: error instanceof Error ? error.message : String(error)
        });
      }
    }
    
    // Also use performance characteristics from database
    if (modelInfo) {
      enhanced.averageLatency = modelInfo.averageLatencyMs || enhanced.averageLatency;
      enhanced.maxConcurrency = modelInfo.maxConcurrency || enhanced.maxConcurrency;
      enhanced.supportsBatching = modelInfo.supportsBatching || enhanced.supportsBatching;
      enhanced.costPerToken = modelInfo.inputCostPer1kTokens ? modelInfo.inputCostPer1kTokens / 1000 : enhanced.costPerToken;
    }
    
    // Provider-specific enhancements based on model patterns (fallback for models not in DB)
    // These are inference-based on model naming patterns
    switch (provider.toLowerCase()) {
      case 'openai':
        if (!modelInfo) {
          enhanced.responsesAPI = modelId.includes('gpt-5') || modelId.includes('gpt-4.1') || modelId.includes('gpt-4o');
          enhanced.canvas = modelId.includes('gpt-4o') || modelId.includes('gpt-5');
          enhanced.webSearch = true;
          enhanced.codeInterpreter = true;
        }
        enhanced.averageLatency = 800; // ms
        enhanced.maxConcurrency = 50;
        enhanced.supportsBatching = false;
        break;
        
      case 'amazon-bedrock': // Claude and other models via Bedrock
        if (!modelInfo) {
          enhanced.promptCaching = modelId.includes('claude-3') || modelId.includes('claude-4') || modelId.includes('claude-opus') || modelId.includes('claude-sonnet');
          enhanced.artifacts = modelId.includes('claude-3.5') || modelId.includes('claude-4') || modelId.includes('claude-opus') || modelId.includes('claude-sonnet');
          enhanced.computerUse = modelId.includes('computer-use');
        }
        enhanced.averageLatency = 1200; // ms
        enhanced.maxConcurrency = 20;
        enhanced.supportsBatching = true;
        break;
        
      case 'google':
        if (!modelInfo) {
          enhanced.contextCaching = modelId.includes('gemini-2') || modelId.includes('gemini-1.5');
          enhanced.grounding = true;
          enhanced.codeExecution = true;
          enhanced.workspaceTools = true;
        }
        enhanced.averageLatency = 600; // ms
        enhanced.maxConcurrency = 100;
        enhanced.supportsBatching = true;
        break;
        
      case 'azure':
        if (!modelInfo) {
          // Azure mirrors OpenAI capabilities
          enhanced.webSearch = true;
          enhanced.codeInterpreter = true;
        }
        enhanced.averageLatency = 900; // ms
        enhanced.maxConcurrency = 30;
        enhanced.supportsBatching = false;
        break;
    }
    
    // Get pricing info from database or use estimates
    enhanced.costPerToken = await this.getModelCostFromDatabase(provider, modelId);
    
    // Apply user preferences
    if (options.enableCaching === false) {
      enhanced.promptCaching = false;
      enhanced.contextCaching = false;
    }
    
    return enhanced;
  }
  
  /**
   * Wrap the base model with Nexus-specific features
   */
  private async wrapWithNexusFeatures(
    model: LanguageModel,
    config: {
      provider: string;
      modelId: string;
      capabilities: NexusModelCapabilities;
      options: NexusModelOptions;
      requestId: string;
    }
  ): Promise<NexusLanguageModel> {
    const { provider, modelId, capabilities, options, requestId } = config;
    
    // Get model info from database for pricing and metadata
    const modelInfo = await this.getModelInfoFromDatabase(provider, modelId);
    
    // Create enhanced model wrapper
    const nexusModel: NexusLanguageModel = {
      model,
      capabilities,
      providerMetadata: {} as any,
      enableCaching: undefined,
      getCacheMetrics: undefined,
      estimateCost: undefined
    };
    
    // Add Nexus metadata
    nexusModel.capabilities = capabilities;
    nexusModel.providerMetadata = {
      provider,
      modelId,
      pricing: {
        inputCostPerToken: modelInfo?.inputCostPer1kTokens ? modelInfo.inputCostPer1kTokens / 1000 : capabilities.costPerToken || 0,
        outputCostPerToken: modelInfo?.outputCostPer1kTokens ? modelInfo.outputCostPer1kTokens / 1000 : (capabilities.costPerToken || 0) * 1.5,
        cachingDiscount: modelInfo?.cachedInputCostPer1kTokens 
          ? 1 - (modelInfo.cachedInputCostPer1kTokens / (modelInfo.inputCostPer1kTokens || 1))
          : this.getCachingDiscount(provider)
      },
      limits: {
        maxTokens: modelInfo?.maxTokens || capabilities.maxTokens || 4000,
        maxRequests: modelInfo?.maxConcurrency || capabilities.maxConcurrency || 10,
        contextWindow: modelInfo?.maxTokens || await this.getContextWindow(provider, modelId)
      }
    };
    
    // Add caching methods if supported
    if (capabilities.promptCaching || capabilities.contextCaching) {
      nexusModel.enableCaching = () => {
        this.responseCache.enableForModel(provider, modelId, options.conversationId);
      };
      
      nexusModel.getCacheMetrics = async () => {
        return await this.responseCache.getMetrics(provider, modelId, options.conversationId);
      };
    }
    
    // Add cost estimation
    nexusModel.estimateCost = (tokens: number) => {
      const inputCost = nexusModel.providerMetadata.pricing?.inputCostPerToken || 0;
      const outputCost = nexusModel.providerMetadata.pricing?.outputCostPerToken || 0;
      // Rough estimate: 60% input, 40% output
      const baseCost = tokens * (inputCost * 0.6 + outputCost * 0.4);
      const discount = this.responseCache.isEnabled(provider, modelId) 
        ? (nexusModel.providerMetadata.pricing?.cachingDiscount || 0) 
        : 0;
      return baseCost * (1 - discount);
    };
    
    return nexusModel;
  }
  
  /**
   * Get available capabilities for a provider/model combination
   */
  async getAvailableCapabilities(provider: string, modelId: string): Promise<NexusModelCapabilities> {
    const baseCapabilities = await createProviderModelWithCapabilities(provider, modelId);
    return this.enhanceCapabilities(provider, modelId, baseCapabilities.capabilities, {});
  }
  
  /**
   * Recommend optimal provider for given requirements
   */
  async recommendProvider(requirements: {
    priority: 'cost' | 'speed' | 'quality' | 'features';
    features?: string[];
    maxCost?: number;
    maxLatency?: number;
  }): Promise<{ provider: string; modelId: string; score: number }[]> {
    const providers = ['openai', 'google', 'amazon-bedrock', 'azure'];
    const recommendations: { provider: string; modelId: string; score: number }[] = [];
    
    for (const provider of providers) {
      const models = await this.getModelsForProvider(provider);
      for (const modelId of models) {
        const capabilities = await this.getAvailableCapabilities(provider, modelId);
        const score = this.calculateProviderScore(capabilities, requirements);
        
        if (score > 0) {
          recommendations.push({ provider, modelId, score });
        }
      }
    }
    
    return recommendations.sort((a, b) => b.score - a.score);
  }
  
  // Private database-driven helper methods
  
  /**
   * Get model information from database
   */
  private async getModelInfoFromDatabase(provider: string, modelId: string): Promise<any> {
    try {
      const result = await executeSQL(`
        SELECT * FROM ai_models 
        WHERE provider = $1 AND model_id = $2 AND active = true
        LIMIT 1
      `, [provider, modelId]);
      
      if (result.length > 0) {
        return transformSnakeToCamel(result[0]);
      }
      
      return null;
    } catch (error) {
      log.warn('Failed to get model info from database', {
        provider,
        modelId,
        error: error instanceof Error ? error.message : String(error)
      });
      return null;
    }
  }
  
  /**
   * Get model cost from database or use provider-based estimates
   */
  private async getModelCostFromDatabase(provider: string, modelId: string): Promise<number> {
    try {
      // First check if we have the model in database with pricing metadata
      const result = await executeSQL(`
        SELECT metadata->'pricing'->'cost_per_token' as cost_per_token
        FROM ai_models 
        WHERE provider = $1 AND model_id = $2 AND active = true
        LIMIT 1
      `, [provider, modelId]);
      
      if (result.length > 0 && result[0].cost_per_token) {
        return parseFloat(result[0].cost_per_token);
      }
      
      // Fallback to provider-based estimates
      return this.estimateCostPerToken(provider, modelId);
    } catch (error) {
      log.warn('Failed to get model cost from database', {
        provider,
        modelId,
        error: error instanceof Error ? error.message : String(error)
      });
      return this.estimateCostPerToken(provider, modelId);
    }
  }
  
  /**
   * Estimate cost per token based on provider and model patterns
   */
  private estimateCostPerToken(provider: string, modelId: string): number {
    switch (provider.toLowerCase()) {
      case 'openai':
        if (modelId.includes('gpt-5')) return 0.00006;
        if (modelId.includes('gpt-4.1')) return 0.00005;
        if (modelId.includes('gpt-4o')) return 0.00003;
        if (modelId.includes('gpt-4')) return 0.00005;
        return 0.000002;
        
      case 'amazon-bedrock':
        if (modelId.includes('claude-opus')) return 0.000015;
        if (modelId.includes('claude-3.5-sonnet') || modelId.includes('claude-sonnet')) return 0.000003;
        if (modelId.includes('claude-3-haiku') || modelId.includes('claude-haiku')) return 0.00000025;
        if (modelId.includes('deepseek')) return 0.0000002;
        return 0.000008;
        
      case 'google':
        if (modelId.includes('gemini-2.5')) return 0.0000025;
        if (modelId.includes('gemini-2.0-flash')) return 0.0000015;
        if (modelId.includes('gemini-1.5-pro')) return 0.00000125;
        if (modelId.includes('gemini-1.5-flash')) return 0.000000075;
        return 0.000001;
        
      case 'azure':
        // Azure typically costs same as OpenAI with small premium
        return this.estimateCostPerToken('openai', modelId) * 1.1;
        
      default:
        return 0.000001;
    }
  }
  
  /**
   * Get caching discount based on provider
   */
  private getCachingDiscount(provider: string): number {
    switch (provider.toLowerCase()) {
      case 'anthropic':
      case 'amazon-bedrock':
        return 0.9; // 90% discount with prompt caching
      case 'google':
        return 0.75; // 75% discount with context caching
      default:
        return 0;
    }
  }
  
  /**
   * Get context window from database or estimate
   */
  private async getContextWindow(provider: string, modelId: string): Promise<number> {
    try {
      const result = await executeSQL(`
        SELECT max_tokens FROM ai_models 
        WHERE provider = $1 AND model_id = $2 AND active = true
        LIMIT 1
      `, [provider, modelId]);
      
      if (result.length > 0 && result[0].max_tokens) {
        return result[0].max_tokens;
      }
    } catch (error) {
      log.warn('Failed to get context window from database', {
        provider,
        modelId,
        error: error instanceof Error ? error.message : String(error)
      });
    }
    
    // Fallback estimates
    switch (provider.toLowerCase()) {
      case 'openai':
        if (modelId.includes('gpt-5')) return 200000;
        if (modelId.includes('gpt-4.1')) return 1000000;
        if (modelId.includes('gpt-4o')) return 128000;
        return 8000;
      case 'amazon-bedrock':
        if (modelId.includes('claude-opus') || modelId.includes('claude-sonnet')) return 200000;
        if (modelId.includes('claude-3.5') || modelId.includes('claude-4')) return 200000;
        if (modelId.includes('deepseek')) return 128000;
        return 100000;
      case 'google':
        if (modelId.includes('gemini-2')) return 2000000;
        if (modelId.includes('gemini-1.5')) return 1000000;
        return 32000;
      case 'azure':
        return this.getContextWindow('openai', modelId);
      default:
        return 8000;
    }
  }
  
  /**
   * Get available models for a provider from database
   */
  private async getModelsForProvider(provider: string): Promise<string[]> {
    try {
      const result = await executeSQL(`
        SELECT model_id FROM ai_models 
        WHERE provider = $1 AND active = true AND chat_enabled = true
        ORDER BY name
      `, [provider]);
      
      if (result.length > 0) {
        return result.map((row: any) => row.model_id);
      }
    } catch (error) {
      log.warn('Failed to get models from database', {
        provider,
        error: error instanceof Error ? error.message : String(error)
      });
    }
    
    // Return empty array if no models found in database
    return [];
  }
  
  private calculateProviderScore(
    capabilities: NexusModelCapabilities,
    requirements: {
      priority: 'cost' | 'speed' | 'quality' | 'features';
      features?: string[];
      maxCost?: number;
      maxLatency?: number;
    }
  ): number {
    let score = 0;
    
    // Check hard constraints
    if (requirements.maxCost && (capabilities.costPerToken || 0) > requirements.maxCost) {
      return 0;
    }
    
    if (requirements.maxLatency && (capabilities.averageLatency || 0) > requirements.maxLatency) {
      return 0;
    }
    
    // Score based on priority
    switch (requirements.priority) {
      case 'cost':
        score = 100 - ((capabilities.costPerToken || 0) * 100000);
        break;
      case 'speed':
        score = 100 - ((capabilities.averageLatency || 0) / 50);
        break;
      case 'quality':
        score = capabilities.supportsReasoning ? 100 : 50;
        score += capabilities.supportsThinking ? 20 : 0;
        break;
      case 'features':
        score = this.countMatchingFeatures(capabilities, requirements.features || []) * 10;
        break;
    }
    
    return Math.max(0, score);
  }
  
  private countMatchingFeatures(capabilities: NexusModelCapabilities, requiredFeatures: string[]): number {
    let count = 0;
    
    for (const feature of requiredFeatures) {
      switch (feature) {
        case 'reasoning':
          if (capabilities.supportsReasoning) count++;
          break;
        case 'thinking':
          if (capabilities.supportsThinking) count++;
          break;
        case 'caching':
          if (capabilities.promptCaching || capabilities.contextCaching) count++;
          break;
        case 'web':
          if (capabilities.webSearch || capabilities.grounding) count++;
          break;
        case 'code':
          if (capabilities.codeInterpreter || capabilities.codeExecution) count++;
          break;
        case 'artifacts':
          if (capabilities.artifacts) count++;
          break;
        case 'canvas':
          if (capabilities.canvas) count++;
          break;
        case 'computer':
          if (capabilities.computerUse) count++;
          break;
      }
    }
    
    return count;
  }
}

// Helper classes (simplified implementations)

class ResponseCacheManager {
  private enabledModels = new Set<string>();
  
  enableForModel(provider: string, modelId: string, conversationId?: string) {
    this.enabledModels.add(`${provider}:${modelId}:${conversationId || 'global'}`);
  }
  
  isEnabled(provider: string, modelId: string, conversationId?: string): boolean {
    return this.enabledModels.has(`${provider}:${modelId}:${conversationId || 'global'}`);
  }
  
  async getMetrics(provider: string, modelId: string, conversationId?: string): Promise<CacheMetrics> {
    // This would query the nexus_cache_entries table
    return {
      hitRate: 0.75,
      totalRequests: 100,
      tokensSaved: 50000,
      costSaved: 2.50
    };
  }
}

class CostOptimizer {
  // Placeholder for cost optimization logic
  // Would analyze usage patterns and recommend optimizations
}

class MetricsCollector {
  async recordModelCreation(data: {
    provider: string;
    modelId: string;
    capabilities: NexusModelCapabilities;
    creationTime: number;
    requestId: string;
  }) {
    // This would record metrics to CloudWatch or database
    log.debug('Model creation metrics recorded', data);
  }
}

// Export singleton instance
export const nexusProviderFactory = new NexusProviderFactory();